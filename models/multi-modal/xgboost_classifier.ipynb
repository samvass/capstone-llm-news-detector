{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPR+PYgZmOJFWuCaNT4pFi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samvass/capstone-llm-news-detector/blob/master/models/multi-modal/xgboost_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://forecastegy.com/posts/xgboost-binary-classification-python/"
      ],
      "metadata": {
        "id": "5Jj3NXmzGuYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config ‚öôÔ∏è"
      ],
      "metadata": {
        "id": "oPUG7BepHZhS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wpGanN91Bs6z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as torchvision_transforms\n",
        "from torchvision.models import resnet18\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from joblib import dump"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = dict(\n",
        "    epochs=2,\n",
        "    learning_rate=0.0001,\n",
        "    batch_size=16,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    ai_dataset_path=[\"./newsgpt_dataset.csv\", \"./rewritten_AI_data.csv\"],\n",
        "    real_dataset_path=[\"./cnn_dataset.csv\"],\n",
        "    ai_img_dir=\"./newsgpt_images\",\n",
        "    real_img_dir=\"./cnn_images\",\n",
        ")"
      ],
      "metadata": {
        "id": "ExHpYaOyBxjG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extractor ü§ñ"
      ],
      "metadata": {
        "id": "eEirm5XLHk3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiModalModelFeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiModalModelFeatureExtractor, self).__init__()\n",
        "        self.resnet = resnet18(pretrained=True)\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Freeze the ResNet parameters\n",
        "        for param in self.resnet.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Freeze the BERT parameters\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, image_inputs, text_inputs):\n",
        "        # Process image input\n",
        "        image_features = self.resnet(image_inputs)\n",
        "        image_features = torch.flatten(image_features, 1)  # Flatten the features\n",
        "\n",
        "        # Process text input\n",
        "        text_features = self.bert(**text_inputs).last_hidden_state[:, 0, :]  # Get the [CLS] token's features\n",
        "\n",
        "        # Concatenate features\n",
        "        combined_features = torch.cat((image_features, text_features), dim=1)\n",
        "\n",
        "        return combined_features"
      ],
      "metadata": {
        "id": "LiwkJH1wBxqG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data üìä"
      ],
      "metadata": {
        "id": "dgKJ9IJkHsQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiModalDataset(Dataset):\n",
        "    def __init__(self, dataframe, ai_img_dir, real_img_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "        self.text_idx = dataframe.columns.get_loc('Text')\n",
        "        self.title_idx = dataframe.columns.get_loc('Title')\n",
        "        self.image_idx = dataframe.columns.get_loc('Image')\n",
        "        self.label_idx = dataframe.columns.get_loc('Label')\n",
        "        self.ai_img_dir = ai_img_dir\n",
        "        self.real_img_dir = real_img_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        text = self.dataframe.iloc[idx, self.text_idx]\n",
        "        title = self.dataframe.iloc[idx, self.title_idx]\n",
        "        label = self.dataframe.iloc[idx, self.label_idx]\n",
        "\n",
        "        img_folder = self.ai_img_dir if label == 1 else self.real_img_dir\n",
        "        img_name = os.path.join(img_folder, str(self.dataframe.iloc[idx, self.image_idx]))\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return title, text, image, label"
      ],
      "metadata": {
        "id": "IhRcZNOxEg53"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    create image dataset for loading training images and calculating mean and std of normalization\n",
        "    for image transforms in the MMM\n",
        "\n",
        "    input: dataframe with Image, Label columns\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframe, ai_img_dir, real_img_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.ai_img_dir = ai_img_dir\n",
        "        self.real_img_dir = real_img_dir\n",
        "        self.image_idx = dataframe.columns.get_loc('Image')\n",
        "        self.label_idx = dataframe.columns.get_loc('Label')\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        label = self.dataframe.iloc[idx, self.label_idx]\n",
        "\n",
        "        img_folder = self.ai_img_dir if label == 1 else self.real_img_dir\n",
        "        img_name = os.path.join(img_folder, str(self.dataframe.iloc[idx, self.image_idx]))\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image"
      ],
      "metadata": {
        "id": "_N00VK_6EhAY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms as torchvision_transforms\n",
        "\n",
        "def get_mean_std(loader):\n",
        "    # Variables to accumulate the sum and sum of squares\n",
        "    channel_sum, channel_sum_squared, num_batches = 0, 0, 0\n",
        "\n",
        "    for images in loader:\n",
        "        # Assumes images are of shape (batch_size, num_channels, height, width)\n",
        "        channel_sum += torch.mean(images, dim=[0, 2, 3])\n",
        "        channel_sum_squared += torch.mean(images**2, dim=[0, 2, 3])\n",
        "        num_batches += 1\n",
        "\n",
        "    # Calculate the mean and std dev\n",
        "    mean = channel_sum / num_batches\n",
        "    # std = sqrt(E[X^2] - (E[X])^2)\n",
        "    std = (channel_sum_squared / num_batches - mean ** 2) ** 0.5\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "def get_normalization_values(dataframe, ai_img_dir, real_img_dir):\n",
        "    transforms = torchvision_transforms.Compose([\n",
        "        torchvision_transforms.ToTensor(),\n",
        "        torchvision_transforms.Resize((224, 224)),\n",
        "        torchvision_transforms.CenterCrop(224),\n",
        "    ])\n",
        "\n",
        "    # Assuming ImageDataset is defined elsewhere and correctly handles the dataframe and directories\n",
        "    dataset = ImageDataset(dataframe, ai_img_dir, real_img_dir, transforms)\n",
        "\n",
        "    batch_size = 32\n",
        "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    mean, std = get_mean_std(loader)\n",
        "    return mean, std"
      ],
      "metadata": {
        "id": "k5qwFlulEhCu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(ai_dataset_path, real_dataset_path, ai_img_dir, real_img_dir):\n",
        "\n",
        "    # get the datasets\n",
        "\n",
        "    ai_data = pd.DataFrame()\n",
        "    for dataset in ai_dataset_path:\n",
        "      ai_data = pd.concat([pd.read_csv(dataset), ai_data])\n",
        "\n",
        "    real_data = pd.DataFrame()\n",
        "    for dataset in real_dataset_path:\n",
        "      real_data = pd.concat([pd.read_csv(dataset), real_data])\n",
        "\n",
        "    combined_data = pd.concat([ai_data, real_data])\n",
        "\n",
        "    mean, std = get_normalization_values(combined_data[['Image', 'Label']], ai_img_dir, real_img_dir)\n",
        "\n",
        "    print(mean, std)\n",
        "\n",
        "    transform = torchvision_transforms.Compose([\n",
        "        torchvision_transforms.Resize(256),\n",
        "        torchvision_transforms.CenterCrop(224),\n",
        "        torchvision_transforms.ToTensor(),\n",
        "        torchvision_transforms.Normalize(mean=mean, std=std),\n",
        "    ])\n",
        "\n",
        "    # create dataset class\n",
        "    dataset = MultiModalDataset(\n",
        "        dataframe=combined_data,\n",
        "        ai_img_dir=ai_img_dir,\n",
        "        real_img_dir=real_img_dir,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "0ySVBrNNEhFR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing üß™"
      ],
      "metadata": {
        "id": "GZfK9ai8H8vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, X_test, y_test):\n",
        "  accuracy = model.score(X_test, y_test)\n",
        "  print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "  y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  # Calculate log loss\n",
        "  logloss = log_loss(y_test, y_pred_proba)\n",
        "  print(f\"Log Loss: {logloss}\")\n",
        "\n",
        "  # Calculate ROC AUC Score\n",
        "  roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "  print(f\"ROC AUC Score: {roc_auc}\")"
      ],
      "metadata": {
        "id": "lJ-hEKoZBxxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline üòé"
      ],
      "metadata": {
        "id": "eFAvrZnXHxHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make():\n",
        "  dataset = get_data(\n",
        "        config[\"ai_dataset_path\"],\n",
        "        config[\"real_dataset_path\"],\n",
        "        config[\"ai_img_dir\"],\n",
        "        config[\"real_img_dir\"],\n",
        "      )\n",
        "\n",
        "  data_loader = DataLoader(dataset, batch_size=config[\"batch_size\"])\n",
        "  return data_loader"
      ],
      "metadata": {
        "id": "vVHhEhsJIOE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_pipeline(config):\n",
        "  data_loader = make(config)\n",
        "\n",
        "  feature_extractor = MultiModalModelFeatureExtractor()\n",
        "\n",
        "  features_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  # gather x, y values\n",
        "  for _, texts, images, labels in data_loader:\n",
        "    combined_features = feature_extractor(images, texts)\n",
        "    features_list.append(combined_features)\n",
        "    labels_list.append(labels.numpy())\n",
        "\n",
        "  X = np.vstack(features_list)\n",
        "  y = np.vstack(labels_list)\n",
        "\n",
        "  # split data\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  # training\n",
        "  model = XGBClassifier(objective='binary:logistic')\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # testing\n",
        "  test(model, X_test, y_test)\n",
        "\n",
        "  #save the model\n",
        "  dump(model, '/content/drive/MyDrive/xgb_model.joblib')"
      ],
      "metadata": {
        "id": "_QKDPykfIGyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A-hi3xFuJZsj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}